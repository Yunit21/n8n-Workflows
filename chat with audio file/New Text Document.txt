âš™ï¸ Built an AI workflow that turns audio files into a searchable knowledge base

I recently built an end-to-end automation in n8n that does something really powerful with audio content ğŸ‘‡

ğŸ§ Upload an audio file
â†’ ğŸ“ Automatically transcribed & summarized using AI
â†’ ğŸ§  Stored as embeddings for future Q&A
â†’ ğŸ’¬ Chat with the audio like a document

How the workflow works:

1ï¸âƒ£ User uploads an audio file via a form
2ï¸âƒ£ Audio is sent to AssemblyAI for:

Speech-to-text

Speaker labels

Bullet-point summaries
3ï¸âƒ£ The transcript is:

Chunked

Embedded using Google Gemini

Stored in Pinecone (vector database)
4ï¸âƒ£ File activity is logged in Google Sheets
5ï¸âƒ£ A chatbot retrieves relevant context from Pinecone and answers questions based on the uploaded audio

ğŸ“Œ Result:
You can ask questions about meetings, podcasts, calls, or interviews â€” and get accurate answers directly from the audio content.

Tech stack:

n8n (automation)

AssemblyAI (STT + summarization)

Google Gemini (embeddings + chat)

Pinecone (vector search)

Google Sheets (logging)

This kind of workflow is perfect for:
ğŸ¯ Meeting intelligence
ğŸ¯ Podcast knowledge bases
ğŸ¯ Call analysis
ğŸ¯ Internal documentation from voice data

Automation + AI makes unstructured data actually usable.

#n8n #AIWorkflow #Automation #RAG #VectorDatabase #AssemblyAI #GoogleGemini #NoCode #LLM #AIChatbot
